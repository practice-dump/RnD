This contains learning I gather from [Language models are few short learners](https://arxiv.org/pdf/2005.14165.pdf)  aka GPT3 paper 

To read after this

- [ ] GPT2 paper for architecture
- [ ] Sparse transformer paper to understand attention paper
- [ ] [gradient noise scale to calculate batch size](https://arxiv.org/pdf/1812.06162.pdf)
